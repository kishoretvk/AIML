{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHS97jMMoYe_"
      },
      "source": [
        "Proprietary content. Â©Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Wmkiv1XaphIQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7aDcDX2oYfE",
        "outputId": "4e91428f-0c6a-4326-a107-c770d02c9139"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 12, 'is': 3, 'the': 10, 'first': 2, 'stage': 9, 'of': 5, 'qualification': 7, 'second': 8, 'and': 1, 'third': 11, 'one': 6, 'it': 4, 'again': 0}\n",
            "(4, 13)\n",
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[[0 0 1 1 0 1 0 1 0 1 1 0 1]\n",
            " [0 0 0 1 0 1 0 1 1 1 1 0 1]\n",
            " [0 1 0 0 0 0 1 0 0 0 1 1 0]\n",
            " [1 0 1 1 1 0 0 0 0 1 1 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# list of text documents\n",
        "text = ['This is the first stage of qualification'\n",
        ", 'This is the second stage of qualification '\n",
        ", 'And the third one'\n",
        ", 'Is it the first stage again']\n",
        "# create the transform\n",
        "vectorizer = CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
        "dtype=np.int64, encoding='utf-8', input='content',\n",
        "lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
        "ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
        "strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "tokenizer=None, vocabulary=None)\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "# encode document\n",
        "vector = vectorizer.transform(text)\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(type(vector))\n",
        "print(vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "2bId_aMlqzuN",
        "outputId": "c1f21e08-800e-4ecf-b9cc-35090ee08447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['first', 'is', 'of', 'stage', 'the'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNoFewypoYfH",
        "outputId": "81a41751-a970-4de2-ab3d-6e45475fbf2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# encode another document\n",
        "text2 = [\"the puppy\"]\n",
        "vector = vectorizer.transform(text2)\n",
        "print(vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0RLVdNaoYfH",
        "outputId": "01c85ad8-215a-498f-81ec-037e8c732e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 12, 'is': 3, 'the': 10, 'first': 2, 'stage': 9, 'of': 5, 'qualification': 7, 'second': 8, 'and': 1, 'third': 11, 'one': 6, 'it': 4, 'again': 0}\n",
            "[1.91629073 1.91629073 1.51082562 1.22314355 1.91629073 1.51082562\n",
            " 1.91629073 1.51082562 1.91629073 1.22314355 1.         1.91629073\n",
            " 1.51082562]\n",
            "(1, 13)\n",
            "[[0.         0.         0.41706663 0.33765138 0.         0.41706663\n",
            "  0.         0.41706663 0.         0.33765138 0.27605213 0.\n",
            "  0.41706663]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# list of text documents\n",
        "text = ['This is the first stage of qualification'\n",
        ", 'This is the second stage of qualification '\n",
        ", 'And the third one'\n",
        ", 'Is it the first stage again']\n",
        "# create the transform\n",
        "vectorizer = TfidfVectorizer()\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit(text)\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.idf_)\n",
        "# encode document\n",
        "vector = vectorizer.transform([text[0]])\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf = vectorizer.idf_\n",
        "print(dict(zip(vectorizer.get_feature_names(), idf)))"
      ],
      "metadata": {
        "id": "fWt4TSThubT5",
        "outputId": "f463aef9-0b05-4fe3-818b-ddd24736ea65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'again': 1.916290731874155, 'and': 1.916290731874155, 'first': 1.5108256237659907, 'is': 1.2231435513142097, 'it': 1.916290731874155, 'of': 1.5108256237659907, 'one': 1.916290731874155, 'qualification': 1.5108256237659907, 'second': 1.916290731874155, 'stage': 1.2231435513142097, 'the': 1.0, 'third': 1.916290731874155, 'this': 1.5108256237659907}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggKEhGOWoYfI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Hands_On_Vectorization.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}